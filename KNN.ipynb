{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.03614457831326%\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "K-nearest neighbors algorithm\n",
    "Jason Brownlee, http://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/\n",
    "Implemented by Emma Anderson\n",
    "Written for the Iris dataset\n",
    "ReWritten by Maxwel Gregg for the datatraining.txt\n",
    "\"\"\"\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import operator\n",
    "\n",
    "def euclideanDistance(item1, item2, attributes):\n",
    "    distance = 0\n",
    "    for x in range(attributes):\n",
    "        distance+=(item1[x] - item2[x])**2\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "def getNeighbors(trainingSet, test, k):\n",
    "    distances = []\n",
    "    length = len(test) - 1\n",
    "    for x in range(len(trainingSet)):\n",
    "        dist = euclideanDistance(test, trainingSet[x], length)\n",
    "        distances.append((trainingSet[x], dist))\n",
    "    #sort on the distance, not the data point\n",
    "    distances.sort(key = operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors\n",
    "\n",
    "def getResponse(neighbors):\n",
    "    classVotes = {}\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x][-1]\n",
    "        if response in classVotes:\n",
    "            classVotes[response]+=1\n",
    "        else:\n",
    "            classVotes[response] = 1\n",
    "    sortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse = True)\n",
    "    return sortedVotes[0][0]\n",
    "\n",
    "def getAccuracy(testSet, predictions):\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        if testSet[x][-1] == predictions[x]:\n",
    "            correct+=1\n",
    "    return (correct/float(len(testSet)))*100.0\n",
    "\n",
    "def loadDataset(filename, split, trainingSet, testSet):    \n",
    "    with open(filename, 'r') as csvfile:\n",
    "        lines = csv.reader(csvfile)\n",
    "        dataset = list(lines)\n",
    "        for x in range(1, len(dataset)-1):\n",
    "            #this needs changing for other datasets\n",
    "            del dataset[x][0]\n",
    "            del dataset[x][0]\n",
    "            del dataset[x][0]\n",
    "            del dataset[x][0]\n",
    "            del dataset[x][2]\n",
    "            for y in range(0, 3):\n",
    "                dataset[x][y] = float(dataset[x][y])\n",
    "            if random.random() < split:\n",
    "                trainingSet.append(dataset[x])\n",
    "            else:\n",
    "                testSet.append(dataset[x])\n",
    "\n",
    "def main():\n",
    "    trainingSet = []\n",
    "    testSet = []\n",
    "    split = 0.95\n",
    "    loadDataset('datatraining.txt', split, trainingSet, testSet)\n",
    "    \n",
    "    predictions = []\n",
    "    k = 15\n",
    "    for x in range(len(testSet)):\n",
    "        neighbors = getNeighbors(trainingSet, testSet[x], k)\n",
    "        result = getResponse(neighbors)\n",
    "        predictions.append(result)\n",
    "        #print('predicted:' + str(result) + ', actual:'+str(testSet[x][-1]))\n",
    "    accuracy = getAccuracy(testSet, predictions)\n",
    "    print('Accuracy: ' + str(accuracy) + '%')\n",
    "\n",
    "main()\n",
    "\n",
    "\n",
    "#testSet = [[1, 1, 1, 'a'], [2, 2, 2, 'b'], [3, 3, 3, 'a']]\n",
    "#predictions= ['a', 'a', 'a']\n",
    "#print(getAccuracy(testSet, predictions))\n",
    "\n",
    "#trainingSet = []\n",
    "#testSet = []\n",
    "#loadDataset('iris.txt', 0.9, trainingSet, testSet)\n",
    "#print(len(trainingSet))\n",
    "#print(len(testSet))\n",
    "\n",
    "#data1 = [2, 2, 2, 'a']\n",
    "#data2 =[4, 4, 4, 'b']\n",
    "#distance = euclideanDistance(data1, data2, 3)\n",
    "#print(distance)\n",
    "\n",
    "#trainSet = [[2, 2, 2, 'a'], [4, 4, 4, 'b']]\n",
    "#test = [5, 5, 5]\n",
    "#k=1\n",
    "#print(getNeighbors(trainSet, test, k))\n",
    "\n",
    "#neighbors = [[1, 1, 1, 'a'], [2, 2, 2, 'a'], [3, 3, 3, 'b']]\n",
    "#response = getResponse(neighbors)\n",
    "#print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To personalize this function for the 'datatraining' dataset I had to change a couple of things.  First I changed the main function from loading the 'iris' dataset to 'datatraining'.  I then deleted the first two columns from the data set because they didn't contribute to the lab and were not defined by integers.  I then changed the range from 0-8 to 0-6 so that my list index was in range.  The rest of manipulations I made are stated below during my testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. After testing various combinations of the different attributes I found that carbon dioxide level and light in the room are the only factors that are very important in this dataset for the program to predict correctly if the room is occupied or not.  To find this I systematically eliminated columns as I gathered the accuracy rates.  To gather the accuracy rates I ran the function ten times and collected then accuracy rates and averaged those ten numbers.  While I was eliminating columns I noticed that the accuracy rate was not changing much after eliminating them... That is until I got to light.  When I got rid of light the average went from around 98% to 70%.  I knew at that point that the light in the room was very important in predicting if there is somebody in the room or not.  I then kept light in the data and started working from the back.  I took out humidity ratio and the average stayed around 98%.  Then when I tried to take out carbon dioxide the accuracy went down near 70% again.  So I found after these tests that Co2 and Light levels are the only two things the function needs to predict with around a 98% accuracy rate if sombody is inside the room or not.  This makes sense to me in a real world sense because when someone enters a room the normally will turn on a light or open blinds or do something of the sort to increase the light in the room so that they can see better.  The carbon dioxide factor seemed obvious because humans exhale carbon dioxide so if someone was in a room the Co2 levels should spike making it easy for the function to precict very accuratly.  So, in conclusion, Carbon Dioxide and Light are the two most important factors in determining if someone is in a room or not.\n",
    "\n",
    "2. I decided to test the different K values after the first part because if the only things that are important are Co2 and Light, then why would it be important to use any of the other factors since they didnt add any accuracy.  So I found the best value of K in the same sort of way I found the important factors.  I started by testing k = 1 ten times.  I then averaged these ten values to get a values that represents the accuracy of k = 1.  I then did this same process until k = 15.  K=1 turned out to be 98.83801% accuracy, k=2: 98.12066, k=3: 98.73376, k=4: 98.40909, k=5: 98.49624, k=6: 99.46666, k=7: 97.75561, k=8: 99.03846, k=9: 98.84526, k=10: 99.21052, k=11: 98.49624, k=12: 99.71671, k=13: 98.05352, k=14: 99.03147, k=15: 99.25558.  After finding these values it turns out when K=12 the function predicts the most accurate.  But even though this is true I don't think it is enough evidence to make a claim about this because the results were so varied.  What I mean by this is values of k like 6, 8, 10, 12, and 14 all were in the 99% accuracy rate, but these values are not really correlated at all nor have enough differences from the rest of the data to be significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
